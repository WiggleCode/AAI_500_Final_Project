{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f2999-9dbd-453b-8f7f-33554fca9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"archive/train.csv\" )\n",
    "\n",
    "# Map target to binary\n",
    "if \"churn\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'churn' column in the training CSV.\")\n",
    "df[\"churn_binary\"] = df[\"churn\"].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "X = df.drop(columns=[\"churn\", \"churn_binary\"])\n",
    "y = df[\"churn_binary\"]\n",
    "\n",
    "display(df.head())\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Target positive rate:\", y.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a468d140-6a3b-45fe-be31-d97848b479c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train split 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numerical:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac7067-de75-4375-a3b2-7b7aa067cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "numeric_transformer = Pipeline([(\"scaler\", StandardScaler())])\n",
    "categorical_transformer = Pipeline([(\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"num\", numeric_transformer, num_cols),\n",
    "     (\"cat\", categorical_transformer, cat_cols)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc2e43-d672-425a-b2f2-55a5a5c680bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "pipe_lr = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300, class_weight=\"balanced\", random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "print(\"Models trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54746b05-9519-4c83-8641-db52254ce9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate best model\n",
    "proba_lr = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "proba_rf = pipe_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_lr = roc_auc_score(y_test, proba_lr)\n",
    "auc_rf = roc_auc_score(y_test, proba_rf)\n",
    "\n",
    "if auc_rf >= auc_lr:\n",
    "    best_name, best_model, y_proba = \"RandomForest\", pipe_rf, proba_rf\n",
    "else:\n",
    "    best_name, best_model, y_proba = \"LogisticRegression\", pipe_lr, proba_lr\n",
    "\n",
    "print(f\"Best model: {best_name} | AUC_LR={auc_lr:.3f} | AUC_RF={auc_rf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b2b75-509f-4ed9-b572-73857165d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation 0.5\n",
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "avg_prec = average_precision_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Accuracy={acc:.3f}, Precision={prec:.3f}, Recall={rec:.3f}, \"\n",
    "      f\"F1={f1:.3f}, ROC-AUC={roc_auc:.3f}, PR-AUC(AP)={avg_prec:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f73cc0-9bdd-465b-873c-6526f236ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate graphs\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f\"{best_name} (AUC={roc_auc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\"); plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pr_prec, pr_rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(pr_rec, pr_prec, label=f\"{best_name} (AP={avg_prec:.3f})\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\"); plt.legend(loc=\"lower left\"); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475d924-6da7-4361-8be7-f05fee2df88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "MODEL_PATH = \"churn_model_pipeline.joblib\"\n",
    "import joblib\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "print(f\"Model saved -> {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170651e-1df3-4b47-82d3-980e7875f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try model on test.csv\n",
    "NEW_DATA_CSV = \"archive/test.csv\"\n",
    "new_data = pd.read_csv(NEW_DATA_CSV)\n",
    "proba_new = best_model.predict_proba(new_data)[:, 1]\n",
    "pred_new = (proba_new >= 0.5).astype(int)\n",
    "out = new_data.copy()\n",
    "out[\"churn_proba\"] = proba_new\n",
    "out[\"churn_pred\"] = pred_new\n",
    "out.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Predictions saved to predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca893b3-dd00-4609-8e26-7d091e3328b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tune\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "best_thr, best_f1 = 0.5, -1.0\n",
    "for thr in thresholds:\n",
    "    yp = (y_proba >= thr).astype(int)\n",
    "    f1_thr = f1_score(y_test, yp, zero_division=0)\n",
    "    if f1_thr > best_f1:\n",
    "        best_f1, best_thr = f1_thr, thr\n",
    "print(f\"Best F1={best_f1:.3f} at threshold={best_thr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15dad2-f938-436b-a87c-3714d53157db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate importance graph\n",
    "try:\n",
    "    pipe = best_model\n",
    "except NameError:\n",
    "    pipe = joblib.load(\"churn_model_pipeline.joblib\")\n",
    "\n",
    "# post-preprocessing feature names\n",
    "pre = pipe.named_steps[\"preprocess\"]\n",
    "num_cols, cat_cols = [], []\n",
    "for name, transformer, cols in pre.transformers_:\n",
    "    if name == \"num\":\n",
    "        num_cols = list(cols)\n",
    "    elif name == \"cat\":\n",
    "        cat_cols = list(cols)\n",
    "\n",
    "ohe = pre.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "try:\n",
    "    cat_feature_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "except Exception:\n",
    "    cat_feature_names = list(ohe.get_feature_names(cat_cols))\n",
    "\n",
    "feature_names = list(num_cols) + cat_feature_names\n",
    "\n",
    "# importances\n",
    "clf = pipe.named_steps[\"clf\"]\n",
    "metric_name = \"importance\"\n",
    "\n",
    "if isinstance(clf, RandomForestClassifier):\n",
    "    values = clf.feature_importances_\n",
    "elif isinstance(clf, LogisticRegression):\n",
    "    values = np.abs(clf.coef_.ravel())  # magnitude as importance\n",
    "    metric_name = \"abs_coef\"\n",
    "else:\n",
    "    # Fallback: permutation importance (uses X_test/y_test from earlier cells)\n",
    "    result = permutation_importance(pipe, X_test, y_test, n_repeats=5, random_state=42, n_jobs=1)\n",
    "    values = result.importances_mean\n",
    "    metric_name = \"perm_importance\"\n",
    "\n",
    "feat_df = pd.DataFrame({\"feature\": feature_names, metric_name: values}).sort_values(metric_name, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Top 20\n",
    "topn = 20\n",
    "top_df = feat_df.head(topn).iloc[::-1]  # reverse for barh\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_df[\"feature\"], top_df[metric_name])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(top_df[\"feature\"], top_df[metric_name])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importances_top20.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# Preview\n",
    "feat_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e71bb-47af-4c0f-baf3-b17699c94ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Generation\n",
    "df = pd.read_csv(\"archive/train.csv\")\n",
    "\n",
    "\n",
    "# Data cleaning, string to int\n",
    "df[\"churn\"] = df[\"churn\"].str.strip().str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "y = df[\"churn\"].astype(int)\n",
    "X = df.drop(columns=[\"churn\"])\n",
    "\n",
    "# Restrict to most impactful features\n",
    "selected_features = [\n",
    "    \"number_customer_service_calls\",\n",
    "    \"total_intl_minutes\",\n",
    "    \"total_day_minutes\",\n",
    "    \"total_day_charge\"\n",
    "]\n",
    "X = X[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=6, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=8, random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "\n",
    "    \n",
    "    if name == \"Logistic Regression\":\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_probs = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_probs)\n",
    "    ap_score = average_precision_score(y_test, y_probs)\n",
    "\n",
    "    print(f\"ROC-AUC: {roc_auc:.3f} | PR-AUC(AP): {ap_score:.3f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
    "    plt.title(f\"Confusion Matrix — {name}\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve — {name}\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Precision–Recall Curve\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_probs)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(rec, prec, label=f\"{name} (AP={ap_score:.3f})\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision–Recall Curve — {name}\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
